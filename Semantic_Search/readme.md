- Semantic Search:
    - Design a search mechanism over the ingested files using the processed query.
    - How would you combine both semantic and keyword results?

There are 2 implementations in this directory:
HNSW/ - contains code for a custom HNSW implementation based on the HNSW paper (citations in the relevant file itself)
FAISS/ - contains code for a FAISS based retrieval implementation with the same structure as HNSW class to be swapped in as needed for testing.

The Hierarchical Navigable Small World (HNSW) approach implemented in this system leverages the efficiency of HNSW graphs for approximate nearest neighbor (ANN) search to build a robust and scalable text retrieval system. At its core, the system utilizes embeddings generated by a Sentence Transformer model to represent text chunks in a high-dimensional space. The system grabs the directory of chunks updated whenever a new document is uploaded, embeds them using a sentence bert model, and inserts these embeddings into the HNSW graph, where each node represents a text chunk, and edges connect nodes to their nearest neighbors based on the cosine similarity of their embeddings. This structure allows for efficient traversal of the graph to find the closest matches to a query embedding.

Upon receiving a query, the system preprocesses and converts the query text into an embedding using the same Sentence Transformer model. The search process starts from an entry point at the highest level of the HNSW graph and iteratively descends through the levels, narrowing down the search area until it reaches the base level. At each step, it employs a greedy algorithm to move to the node closest to the query embedding, utilizing priority queues to maintain a dynamic list of candidate nodes. This ensures that the search is both fast and returns high-quality matches, even in a large-scale dataset.

The system is designed with flexibility and scalability in mind. Nodes can be added to the graph dynamically as new text chunks are processed, allowing the index to grow and adapt to new data over time. Furthermore, the implementation supports efficient k-nearest neighbor searches, enabling it to retrieve the top-k most relevant text chunks in response to a query.

Note: The HNSW implementation has certain parameters which require tuning and optimization - due to time constraints, the default parameters are just initial values set for testing, and have not been optimized for best results, just functionality.

I did not implement the semantic + keyword combined search, but a simple way to implement this is to have a separate keyword-search system to query the text chunk database and retrieve the top k text chunks based on keyword matching. I would then merge the results of the semantic and keyword search systems (removing any duplicates) and pass them into the reranker to get the sorted top n chunks.